{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-03-30T10:21:34.887233Z","iopub.status.busy":"2023-03-30T10:21:34.885858Z","iopub.status.idle":"2023-03-30T10:21:34.896251Z","shell.execute_reply":"2023-03-30T10:21:34.895032Z","shell.execute_reply.started":"2023-03-30T10:21:34.887179Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-03-30T10:21:34.899371Z","iopub.status.busy":"2023-03-30T10:21:34.898605Z","iopub.status.idle":"2023-03-30T10:22:21.352922Z","shell.execute_reply":"2023-03-30T10:22:21.351014Z","shell.execute_reply.started":"2023-03-30T10:21:34.899325Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting git+https://github.com/scikit-multiflow/scikit-multiflow\n","  Cloning https://github.com/scikit-multiflow/scikit-multiflow to /tmp/pip-req-build-lmtt7oct\n","  Running command git clone --filter=blob:none --quiet https://github.com/scikit-multiflow/scikit-multiflow /tmp/pip-req-build-lmtt7oct\n","  Resolved https://github.com/scikit-multiflow/scikit-multiflow to commit d073a706b5006cba2584761286b7fa17e74e87be\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: sortedcontainers>=1.5.7 in /home/dbkamgangu/Documents/Internship/anomaly-detection-in-data-stream/venv/lib/python3.9/site-packages (from scikit-multiflow==0.6.dev0) (2.4.0)\n","Requirement already satisfied: numpy>=1.14.0 in /home/dbkamgangu/Documents/Internship/anomaly-detection-in-data-stream/venv/lib/python3.9/site-packages (from scikit-multiflow==0.6.dev0) (1.23.5)\n","Requirement already satisfied: scipy>=1.0.0 in /home/dbkamgangu/Documents/Internship/anomaly-detection-in-data-stream/venv/lib/python3.9/site-packages (from scikit-multiflow==0.6.dev0) (1.10.1)\n","Requirement already satisfied: matplotlib>=2.0.0 in /home/dbkamgangu/Documents/Internship/anomaly-detection-in-data-stream/venv/lib/python3.9/site-packages (from scikit-multiflow==0.6.dev0) (3.6.3)\n","Requirement already satisfied: scikit-learn>=0.20 in /home/dbkamgangu/Documents/Internship/anomaly-detection-in-data-stream/venv/lib/python3.9/site-packages (from scikit-multiflow==0.6.dev0) (1.2.2)\n","Requirement already satisfied: pandas>=0.25.3 in /home/dbkamgangu/Documents/Internship/anomaly-detection-in-data-stream/venv/lib/python3.9/site-packages (from scikit-multiflow==0.6.dev0) (1.4.4)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /home/dbkamgangu/Documents/Internship/anomaly-detection-in-data-stream/venv/lib/python3.9/site-packages (from matplotlib>=2.0.0->scikit-multiflow==0.6.dev0) (1.4.4)\n","Requirement already satisfied: pyparsing>=2.2.1 in /home/dbkamgangu/Documents/Internship/anomaly-detection-in-data-stream/venv/lib/python3.9/site-packages (from matplotlib>=2.0.0->scikit-multiflow==0.6.dev0) (3.0.9)\n","Requirement already satisfied: packaging>=20.0 in /home/dbkamgangu/Documents/Internship/anomaly-detection-in-data-stream/venv/lib/python3.9/site-packages (from matplotlib>=2.0.0->scikit-multiflow==0.6.dev0) (23.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /home/dbkamgangu/Documents/Internship/anomaly-detection-in-data-stream/venv/lib/python3.9/site-packages (from matplotlib>=2.0.0->scikit-multiflow==0.6.dev0) (1.0.7)\n","Requirement already satisfied: fonttools>=4.22.0 in /home/dbkamgangu/Documents/Internship/anomaly-detection-in-data-stream/venv/lib/python3.9/site-packages (from matplotlib>=2.0.0->scikit-multiflow==0.6.dev0) (4.39.2)\n","Requirement already satisfied: cycler>=0.10 in /home/dbkamgangu/Documents/Internship/anomaly-detection-in-data-stream/venv/lib/python3.9/site-packages (from matplotlib>=2.0.0->scikit-multiflow==0.6.dev0) (0.11.0)\n","Requirement already satisfied: pillow>=6.2.0 in /home/dbkamgangu/Documents/Internship/anomaly-detection-in-data-stream/venv/lib/python3.9/site-packages (from matplotlib>=2.0.0->scikit-multiflow==0.6.dev0) (9.4.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /home/dbkamgangu/Documents/Internship/anomaly-detection-in-data-stream/venv/lib/python3.9/site-packages (from matplotlib>=2.0.0->scikit-multiflow==0.6.dev0) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /home/dbkamgangu/Documents/Internship/anomaly-detection-in-data-stream/venv/lib/python3.9/site-packages (from pandas>=0.25.3->scikit-multiflow==0.6.dev0) (2022.7.1)\n","Requirement already satisfied: joblib>=1.1.1 in /home/dbkamgangu/Documents/Internship/anomaly-detection-in-data-stream/venv/lib/python3.9/site-packages (from scikit-learn>=0.20->scikit-multiflow==0.6.dev0) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /home/dbkamgangu/Documents/Internship/anomaly-detection-in-data-stream/venv/lib/python3.9/site-packages (from scikit-learn>=0.20->scikit-multiflow==0.6.dev0) (3.1.0)\n","Requirement already satisfied: six>=1.5 in /home/dbkamgangu/Documents/Internship/anomaly-detection-in-data-stream/venv/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->scikit-multiflow==0.6.dev0) (1.15.0)\n","Building wheels for collected packages: scikit-multiflow\n","  Building wheel for scikit-multiflow (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for scikit-multiflow: filename=scikit_multiflow-0.6.dev0-cp39-cp39-linux_x86_64.whl size=1235338 sha256=8d599a6ab1fe7fc929b571f0a5c6b077ec5b054a2fbf78d14922a454a6c0398d\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-8txt67k3/wheels/5a/04/72/1a42ec39dbeeffefe263284c37dfd644718c13ad0e63f69ac6\n","Successfully built scikit-multiflow\n","Installing collected packages: scikit-multiflow\n","Successfully installed scikit-multiflow-0.6.dev0\n"]}],"source":["!pip install -U git+https://github.com/scikit-multiflow/scikit-multiflow"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-03-30T10:22:21.359205Z","iopub.status.busy":"2023-03-30T10:22:21.358697Z","iopub.status.idle":"2023-03-30T10:22:23.426565Z","shell.execute_reply":"2023-03-30T10:22:23.424879Z","shell.execute_reply.started":"2023-03-30T10:22:21.359150Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'skmultiflow'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[3], line 61\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39m\"\"\"# Part 1 - Main class - IsolationForestStream\"\"\"\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# To implement this class, we took inspiration from Scikit-MultiFLow HSTrees implementation to follow its requirements.\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mskmultiflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseSKMObject, ClassifierMixin\n\u001b[1;32m     62\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mskmultiflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m check_random_state\n\u001b[1;32m     63\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'skmultiflow'"]}],"source":["# -*- coding: utf-8 -*-\n","\"\"\"Notebook_test_iForestASD_Scikitmultiflow.ipynb\n","\n","Automatically generated by Colaboratory.\n","\n","Original file is located at\n","    https://colab.research.google.com/drive/1APZBgZ0fuHufYWM5QKqFhR7cpPs0bF2T\n","\n","# iForestASD :  Unsupervised Anomaly Detection with Scikit-MultiFlow\n","\n","An Implementation of Unsupervised Anomaly Detection with Isolation Forest in Scikit-MultiFlow with Sliding Windows \\& drift detection\n","\n","\n","## References :\n","\n"," - An Anomaly Detection Approach Based on Isolation Forest  for Streaming Data using Sliding Window (Ding \\& Fei, 2013) https://www.sciencedirect.com/science/article/pii/S1474667016314999\n"," \n"," - Isolation-based Anomaly Detection (Liu, Ting \\& Zhou, 2011) https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/tkdd11.pdf\n","\n"," - Scikit MultiFlow HalfSpace Trees Implementation - “Fast anomaly detection for streaming data,” in IJCAI Proceedings - S.C.Tan, K.M.Ting, and T.F.Liu, \n"," https://scikit-multiflow.github.io/scikit-multiflow/_autosummary/skmultiflow.anomaly_detection.HalfSpaceTrees.html#id2\n","\n"," - Original implementation of Isolation Forest (not the one in SK-learn) https://github.com/Divya-Bhargavi/isolation-forest\n","\"\"\"\n","\n","\n","\"\"\"# Notebook File Structure  is the following\n","\n","Part 1 - Main Class contians\n","  - Init,\n","  - Partial_fit,\n","  -  Update_model,\n","  - Predict methods which use the anomaly_score methods of the iForest class\n","\n","Part 2 - Isolation Forest class (re-used) and main functions\n"," - \n","\n","Part 3 - Testing some examples and comparison of HS-Trees and IsolatationForestStream \n","- on synthetic \n","- on Real (HTTP) data.\n","\n","## Import lib and packages\n","\"\"\"\n","\n","\n","\"\"\"## Install Cyphion then load the Scikit-multiflow latest release from Github\"\"\"\n","\n","# !pip install scikit-multiflow\n","\n","\n","#!pip install -U git+https://github.com/scikit-multiflow/scikit-multiflow\n","\n","\n","\"\"\"# Part 1 - Main class - IsolationForestStream\"\"\"\n","\n","# To implement this class, we took inspiration from Scikit-MultiFLow HSTrees implementation to follow its requirements.\n","\n","\n","\n","\n","from skmultiflow.core import BaseSKMObject, ClassifierMixin\n","from skmultiflow.utils import check_random_state\n","import numpy as np\n","import random\n","from skmultiflow.drift_detection.adwin import ADWIN\n","class IsolationForestStream(BaseSKMObject, ClassifierMixin):\n","\n","    \"\"\"\n","    This code implements  Anomaly Detection Approach Based on Isolation Forest Algorithm for Streaming Data Using Sliding Window (Ding \\& Fei, 2013) [3]\n","\n","      Each sample has an anomaly score is computed based on Isolation Forest anomaly based approach [2]. The concept of Isolation forest [1]\n","      consists on  isolating observations by randomly selecting a feature\n","      and then randomly selecting a split value between the maximum and minimum\n","      values of the selected feature.\n","\n","      Model is updated of a Drift has been detected based on a input drift threshold. The drift detection approach is proposed by [2] \n","      and works as follow : if the averaged anomaly score between two successive sliding windows is highter than the drift threshold (u), \n","      then the previous model is completely discarded and a new model is build as an isolation forest on latest sliding windows stream.\n","\n","\n","    Parameters\n","\n","      ---------\n","\n","      n_estimators: int, optional (default=25)\n","\n","         Number of trees in the ensemble.\n","\n","         't' in the original paper.\n","\n","\n","\n","      window_size: int, optional (default=100)\n","\n","          The window size of the stream.\n","\n","          ψ, 'Psi' in the original paper.   \n","\n","  ## Optional       \n","\n","      anomaly_threshold: double, optional (default=0.5)\n","\n","          The threshold for declaring anomalies.\n","\n","          Any instance prediction probability above this threshold will be declared as an anomaly.\n","\n","      drift_threshold: double, optional (default=0.5)\n","\n","          The threshold for detecting Drift and update the model.\n","\n","         If the averaged anomaly score between two successive sliding windows is highter than the threshold (u), \n","      then the previous model is completely discarded and a new model is build as an isolation forest on latest sliding windows stream.\n","      This parameters is supposed to be know by an expert domain, depending on data set.\n","\n","  ## Other Attributes\n","\n","      ensemble : Isolation Tree Ensemble\n","\n","          Contain an Isolation Tree Ensemble object, current model for   IsolationForestStream\n","\n","      sample_size : int\n","\n","          Number of sample seen since the update\n","\n","      anomaly_rate : float\n","\n","          Rate of the anomalies in the previous sliding window (AnomalyRate in the original paper iForestASD)\n","\n","      prec_window & window : numpy.ndarray of shape (n_samples, self.window_size)\n","\n","          The previous and current window of data\n","\n","      cpt : int\n","\n","          Counter, if the n_estimator is higher than its, it will fit\n","\n","      References\n","      ----------\n","\n","      [1] Liu, Fei Tony, Ting, Kai Ming and Zhou, Zhi-Hua.        \n","  “Isolation forest.” Data Mining, 2008. ICDM’08. Eighth IEEE International Conference on.\n","\n","      [2] Liu, Fei Tony, Ting, Kai Ming and Zhou, Zhi-Hua. “Isolation-based anomaly detection.” ACM Transactions on Knowledge Discovery from Data (TKDD) 6.1 (2012): \n","  self.n_estimators\n","\n","      [3] Ding, Zhiguo. (2013) An Anomaly Detection Approach Based on Isolation Forest Algorithm for Streaming Data Using Sliding Window. 12-17. 10.3182/20130902-3-CN-3020.00044. \n","\n","      \"\"\"\n","\n","    def __init__(self, window_size=100, n_estimators=25, anomaly_threshold=0.5,\n","                 drift_threshold=0.5, random_state=None, version=\"AnomalyRate\",\n","                 # Parameters for partial model update\n","                 n_estimators_updated=0.5, updated_randomly=True,\n","                 # Parameters for NDKSWIN\n","                 alpha=0.01, data=None, n_dimensions=1, n_tested_samples=0.1,\n","                 fixed_checked_dimension=False, fixed_checked_sample=False):\n","\n","        super().__init__()\n","\n","        self.n_estimators = n_estimators\n","\n","        self.ensemble = None\n","\n","        self.random_state = random_state\n","\n","        self.window_size = window_size\n","\n","        self.samples_seen = 0\n","\n","        self.anomaly_rate = 0.20\n","\n","        self.anomaly_threshold = anomaly_threshold\n","\n","        self.drift_threshold = drift_threshold\n","\n","        self.window = None\n","\n","        self.prec_window = None\n","\n","        self.cpt = 0\n","        self.version = version\n","        # To count the number of times the model have been updated 0 Not updated and 1 updated\n","        self.model_update = []\n","        # To count the number of times the model have been updated 0 Not updated and 1 updated\n","        self.model_update_windows = []\n","        # Initialisation to know the concerned version of IForestASD\n","        self.model_update.append(version)\n","        # Initialisation to know the number of data seen in the window\n","        self.model_update_windows.append(\"samples_seen_\"+version)\n","        # The percentage of new trees to compute when update on new window\n","        self.n_estimators_updated = int(self.n_estimators*n_estimators_updated)\n","        if n_estimators_updated <= 0.0 or n_estimators_updated > 1.0:\n","            raise ValueError(\"n_estimators_updated must be > 0 and <= 1\")\n","\n","        # If we will choose randomly the trees: True for randomly,\n","        self.updated_randomly = updated_randomly\n","        # False to pick the first (n_estimators- int(n_estimators*n_estimators_updated)) trees\n","\n","        self.alpha = alpha\n","        self.n_dimensions = n_dimensions\n","        self.n_tested_samples = n_tested_samples\n","        self.fixed_checked_dimension = fixed_checked_dimension\n","        self.fixed_checked_sample = fixed_checked_sample\n","        self.first_time_fit = True\n","\n","        # TODO Maurras 27112020: Find a way to optimize the use of ADWIN()\n","        self.adwin = ADWIN()\n","\n","    def partial_fit(self, X, y, classes=None, sample_weight=None):\n","        \"\"\" Partially (incrementally) fit the model.\n","        Parameters\n","        ----------\n","        X : numpy.ndarray of shape (n_samples, n_features)\n","            The features to train the model.\n","        y: numpy.ndarray of shape (n_samples)\n","            An array-like with the class labels of all samples in X.\n","        classes: None\n","            Not used by this method.\n","        sample_weight: None\n","            Not used by this method.\n","        Returns\n","        -------\n","        self\n","        \"\"\"\n","\n","        # get the number of observations\n","        number_instances, _ = X.shape\n","\n","        if (self.samples_seen == 0):\n","            # ToDo ? Give a sample of self.window_size in attribute of iForest\n","            iforest = IsolationTreeEnsemble(\n","                self.window_size, self.n_estimators, self.random_state)\n","            self.ensemble = iforest\n","\n","        for i in range(number_instances):\n","            self._partial_fit(X[i], y[i])\n","\n","        return self\n","\n","    def _partial_fit(self, X, y):\n","        \"\"\" Trains the model on samples X and corresponding targets y.\n","        Private function where actual training is carried on.\n","        Parameters\n","        ----------\n","        X: numpy.ndarray of shape (1, n_features)\n","            Instance attributes.\n","        y: int\n","            Class label for sample X. Not used in this implementaion which is Unsupervised\n","        \"\"\"\n","\n","        \"\"\"\n","          Reshape X and add it to our window if it isn't full.\n","          If it's full, give window to our precedent_window.\n","          If we are at the end our window, fit if we're learning \n","          Check the anomaly score of our window \n","          Update if self.anomaly_rate > self.drift_threshold\n","\n","          \"\"\"\n","        X = np.reshape(X, (1, len(X)))\n","\n","        if self.samples_seen % self.window_size == 0:\n","            # Update the two windows (precedent one and current windows)\n","            self.prec_window = self.window\n","            self.window = X\n","        else:\n","            self.window = np.concatenate((self.window, X))\n","\n","        if self.samples_seen % self.window_size == 0 and self.samples_seen != 0:\n","\n","            if (self.version == \"NDKSWIN\"):\n","                if self.first_time_fit:  # It is the first window\n","                    from source import ndkswin as ndk\n","                    self.ndkswin = ndk.NDKSWIN(alpha=self.alpha, data=self.prec_window, n_dimensions=self.n_dimensions,\n","                                               window_size=self.window_size, stat_size=30,\n","                                               n_tested_samples=self.n_tested_samples,\n","                                               fixed_checked_dimension=self.fixed_checked_dimension,\n","                                               fixed_checked_sample=self.fixed_checked_sample)\n","                    # if(self.cpt<self.n_estimators):\n","                    self.ensemble.fit(self.prec_window)\n","                    # self.cpt += 1\n","                    self.first_time_fit = False\n","                    self.model_update.append(0)\n","                    self.model_update_windows.append(self.samples_seen)\n","                    # print(\"ndkswin created\")\n","                else:\n","                    # print(\"self.samples_seen\")\n","                    # print(self.samples_seen)\n","                    # print(\"self.window_size\")\n","                    # print(self.window_size)\n","                    # print(\"self.window\")\n","                    # print(self.window)\n","                    # print(\"X\")\n","                    # print(X)\n","                    # print(\"prec_window\")\n","                    # print(self.prec_window)\n","\n","                    self.ndkswin.add_element(self.prec_window)\n","                    if self.ndkswin.detected_change():\n","                        self.model_update.append(1)\n","                        self.model_update_windows.append(self.samples_seen)\n","                        # This function will discard completly the old model and create a new one\n","                        self.update_model(self.prec_window)\n","                    else:\n","                        self.model_update.append(0)\n","                        self.model_update_windows.append(self.samples_seen)\n","            else:\n","                # Fit the ensemble if it's not empty\n","                # if(self.cpt<self.n_estimators):\n","                #  self.ensemble.fit(self.prec_window)\n","                #  self.cpt += 1\n","                if self.first_time_fit:  # It is the first window\n","                    self.ensemble.fit(self.prec_window)\n","                    self.first_time_fit = False\n","\n","                if (self.version == \"AnomalyRate\"):\n","                    # print('start AnomalyRate version')\n","                    # Update the current anomaly score\n","                    self.anomaly_rate = self.anomaly_scores_rate(\n","                        self.prec_window)  # Anomaly rate\n","                    # print(self.anomaly_rate) ##\n","                    # Update the model if the anomaly rate is greater than the threshold (u in the original paper [3])\n","                    if self.anomaly_rate > self.drift_threshold:  # Use Anomaly RATE ?\n","                        self.model_update.append(1)\n","                        self.model_update_windows.append(self.samples_seen)\n","                        # This function will discard completly the old model and create a new one\n","                        self.update_model(self.prec_window)\n","                    else:\n","                        self.model_update.append(0)\n","                        self.model_update_windows.append(self.samples_seen)\n","\n","                elif (self.version == \"MAnomalyRate\"):\n","                    # print('start AnomalyRate version')\n","                    # Update the current anomaly score\n","                    self.anomaly_rate = self.anomaly_scores_rate(\n","                        self.prec_window)  # Anomaly rate\n","                    # print(self.anomaly_rate) ##\n","                    # Update the model if the anomaly rate is greater than the threshold (u in the original paper [3])\n","                    if self.anomaly_rate > self.drift_threshold:  # Use Anomaly RATE ?\n","                        self.model_update.append(1)\n","                        self.model_update_windows.append(self.samples_seen)\n","                        # print(\"MIForestASD Before partial_update_model\")\n","                        # This function will discard completly the old model and create a new one\n","                        self.partial_update_model(self.prec_window)\n","                    else:\n","                        self.model_update.append(0)\n","                        self.model_update_windows.append(self.samples_seen)\n","\n","                elif (self.version == \"SADWIN\"):\n","                    # if self.first_time_fit:\n","                    #    from skmultiflow.drift_detection.adwin import ADWIN\n","                    #    adwin = ADWIN()\n","                    #    self.first_time_fit = False\n","                    # print('start sadwin version')\n","                    # TODO MAJ Maurras 04112020 : Modify the way to detect the concept drift using the ADWIN() function availlable in scikitMultiflow\n","                    # from skmultiflow.drift_detection.adwin import ADWIN\n","                    # adwin = ADWIN()\n","                    prec_window_scores = self.ensemble.anomaly_score(\n","                        self.prec_window)\n","                    # print(prec_window_scores)\n","                    # print('Before  add element to adwin')\n","                    drift_detected = False\n","                    # ind = 0\n","                    for score in prec_window_scores:\n","                        # adwin.add_element(prec_window_scores)\n","                        # print(\"added score = \"+ str(score) + \" on index = \"+ str(ind))\n","                        self.adwin.add_element(score)\n","                        # print('start change detection')\n","                        if self.adwin.detected_change():\n","                            # print('Change detected on index = '+ str(ind))\n","                            drift_detected = True\n","                            # print(\"Index = \"+str(i) +\" of the window with data \"+ str(self.prec_window[i]))\n","                            break\n","                        # ind = ind + 1\n","                    if (drift_detected):\n","                        # print('start model updating')\n","                        self.model_update.append(1)\n","                        self.model_update_windows.append(self.samples_seen)\n","                        self.update_model(self.prec_window)\n","                        self.adwin.reset()\n","                    else:\n","                        self.model_update.append(0)\n","                        self.model_update_windows.append(self.samples_seen)\n","\n","                elif (self.version == \"SMADWIN\"):\n","                    # if self.first_time_fit:\n","                    #    from skmultiflow.drift_detection.adwin import ADWIN\n","                    #    adwin = ADWIN()\n","                    #    self.first_time_fit = False\n","                    # print('start sadwin version')\n","                    # TODO MAJ Maurras 04112020 : Modify the way to detect the concept drift using the ADWIN() function availlable in scikitMultiflow\n","                    # from skmultiflow.drift_detection.adwin import ADWIN\n","                    # adwin = ADWIN()\n","                    prec_window_scores = self.ensemble.anomaly_score(\n","                        self.prec_window)\n","                    # print(prec_window_scores)\n","                    # print('Before  add element to adwin')\n","                    drift_detected = False\n","                    # ind = 0\n","                    for score in prec_window_scores:\n","                        # adwin.add_element(prec_window_scores)\n","                        # print(\"added score = \"+ str(score) + \" on index = \"+ str(ind))\n","                        self.adwin.add_element(score)\n","                        # print('start change detection')\n","                        if self.adwin.detected_change():\n","                            # print('Change detected on index = '+ str(ind))\n","                            drift_detected = True\n","                            # print(\"Index = \"+str(i) +\" of the window with data \"+ str(self.prec_window[i]))\n","                            break\n","                        # ind = ind + 1\n","                    if (drift_detected):\n","                        # print('start model updating')\n","                        self.model_update.append(1)\n","                        self.model_update_windows.append(self.samples_seen)\n","                        # print(\"SMADWIN Before partial_update_model\")\n","                        self.partial_update_model(self.prec_window)\n","                        self.adwin.reset()\n","                    else:\n","                        self.model_update.append(0)\n","                        self.model_update_windows.append(self.samples_seen)\n","\n","                elif (self.version == \"PADWIN\"):\n","                    # if self.first_time_fit:\n","                    #    from skmultiflow.drift_detection.adwin import ADWIN\n","                    #    adwin = ADWIN()\n","                    #    self.first_time_fit = False\n","                    # print('start PADWIN version')\n","                    # TODO MAJ Maurras 04112020 : Modify the way to detect the concept drift using the ADWIN() function availlable in scikitMultiflow\n","                    # from skmultiflow.drift_detection.adwin import ADWIN\n","                    # adwin = ADWIN()\n","                    prec_window_predictions = self.predict_simple(\n","                        self.prec_window)\n","                    # print(prec_window_predictions)\n","                    # print('Before  add element to adwin')\n","                    drift_detected = False\n","                    # ind = 0\n","                    for pred in prec_window_predictions:\n","                        # adwin.add_element(prec_window_scores)\n","                        # print(\"added pred = \"+ str(pred))\n","                        self.adwin.add_element(pred)\n","                        # print('start change detection')\n","                        if self.adwin.detected_change():\n","                            # print('Change detected')\n","                            drift_detected = True\n","                            # print(\"Index = \"+str(i) +\" of the window with data \"+ str(self.prec_window[i]))\n","                            break\n","                        # ind = ind + 1\n","                    if (drift_detected):\n","                        # print('start model updating')\n","                        self.model_update.append(1)\n","                        self.model_update_windows.append(self.samples_seen)\n","                        self.update_model(self.prec_window)\n","                        self.adwin.reset()\n","                    else:\n","                        self.model_update.append(0)\n","                        self.model_update_windows.append(self.samples_seen)\n","\n","                elif (self.version == \"PMADWIN\"):\n","                    # if self.first_time_fit:\n","                    #    from skmultiflow.drift_detection.adwin import ADWIN\n","                    #    adwin = ADWIN()\n","                    #    self.first_time_fit = False\n","                    # print('start PADWIN version')\n","                    # TODO MAJ Maurras 04112020 : Modify the way to detect the concept drift using the ADWIN() function availlable in scikitMultiflow\n","                    # from skmultiflow.drift_detection.adwin import ADWIN\n","                    # adwin = ADWIN()\n","                    prec_window_predictions = self.predict_simple(\n","                        self.prec_window)\n","                    # print(prec_window_predictions)\n","                    # print('Before  add element to adwin')\n","                    drift_detected = False\n","                    # ind = 0\n","                    for pred in prec_window_predictions:\n","                        # adwin.add_element(prec_window_scores)\n","                        # print(\"added pred = \"+ str(pred))\n","                        self.adwin.add_element(pred)\n","                        # print('start change detection')\n","                        if self.adwin.detected_change():\n","                            # print('Change detected')\n","                            drift_detected = True\n","                            # print(\"Index = \"+str(i) +\" of the window with data \"+ str(self.prec_window[i]))\n","                            break\n","                        # ind = ind + 1\n","                    if (drift_detected):\n","                        # print('start model updating')\n","                        self.model_update.append(1)\n","                        self.model_update_windows.append(self.samples_seen)\n","                        # print(\"PMADWIN Before partial_update_model\")\n","                        self.partial_update_model(self.prec_window)\n","                        self.adwin.reset()\n","                    else:\n","                        self.model_update.append(0)\n","                        self.model_update_windows.append(self.samples_seen)\n","\n","        self.samples_seen += 1\n","\n","    # def execute_NDKSWIN(stream, window_size=100, window_number=1000):\n","    #  first_window = stream.next_sample(window_size)[0]\n","  # print(first_window)\n","  # print(type(first_window))\n","    #  ndkswin = ndk.NDKSWIN(alpha=0.01, data=first_window, n_dimensions=1, n_tested_samples=0.01,\n","    #                        fixed_checked_dimension = True, fixed_checked_sample=True)\n","  # Store detections\n","  # detections = []\n","  # Process stream via NDKSWIN and print detections\n","  # for i in range(window_number-1):\n","        # data = stream.next_sample(window_size)\n","    #      data = stream.next_sample(window_size)\n","    #      batch = data[0]\n","    #      ndkswin.add_element(batch)\n","    #      if ndkswin.detected_change():\n","        # print(\"\\rIteration {}\".format(i))\n","        # print(\"\\r KSWINReject Null Hyptheses\")\n","    #          detections.append(i)\n","        # ndkswin.reset()\n","        # ndkswin = ndk.NDKSWIN(alpha=0.01, data=batch, n_dimensions=1, n_tested_samples=0.1,\n","        #              fixed_checked_dimension = True, fixed_checked_sample=True)\n","  # print(\"Drift detected in window n° \"+str(detections))\n","  # print(\"Number of detections: \"+str(len(detections)))\n","\n","    def partial_update_model(self, window):\n","        \"\"\" Update the model (fit a new isolation forest) if the current anomaly rate (in the previous sliding window)\n","         is higher than self.drift_threshold\n","            Parameters: \n","              window: numpy.ndarray of shape (self.window_size, n_features)\n","            Re-Initialize our attributes and our ensemble, fit with the current window\n","\n","        \"\"\"\n","\n","        # print(\"In partial_update_model\")\n","        self.is_learning_phase_on = True\n","        iforest = IsolationTreeEnsemble(\n","            self.window_size, self.n_estimators_updated, self.random_state)\n","        # print(\"After new model creation\")\n","        iforest.fit(window)\n","        # print(\"After new model fitting\")\n","        if self.updated_randomly:\n","            # print(\"Randomly choose trees\")\n","            old_trees_idx = random.sample(list(\n","                range(len(self.ensemble.trees))), (self.n_estimators-self.n_estimators_updated))\n","            # print(type(old_trees_idx))\n","        else:\n","            # print(\"First trees\")\n","            old_trees_idx = range(self.n_estimators-self.n_estimators_updated)\n","            # print(type(old_trees_idx))\n","\n","        # print(\"After indices choices\")\n","        # TODO Maurras 26112020: Code à reécrire pour facilement récuperer les arbres à garder sans explicitement utiliser la boucle\n","        for t in old_trees_idx:\n","            iforest.trees.append(self.ensemble.trees[t])\n","        # self.ensemble.trees = np.concatenate((self.ensemble.trees[old_trees_idx],iforest.trees))\n","        self.ensemble.trees = iforest.trees\n","        # print(\"After np.concatenate\")\n","\n","        # self.nb_update = self.nb_update + 1\n","        print(\"\")\n","        print(\"The model was partially updated by training a sub new iForest with the version : \"+self.version)\n","\n","    def update_model(self, window):\n","        \"\"\" Update the model (fit a new isolation forest) if the current anomaly rate (in the previous sliding window)\n","         is higher than self.drift_threshold\n","            Parameters: \n","              window: numpy.ndarray of shape (self.window_size, n_features)\n","            Re-Initialize our attributes and our ensemble, fit with the current window\n","\n","        \"\"\"\n","\n","        # ToDo ? Give a sample of self.window_size in attribute of iForest\n","        # MAJ Maurras 03112020 : No, Leave it like that. Must give all the window to tt construct the forest of itrees.\n","        self.is_learning_phase_on = True\n","        iforest = IsolationTreeEnsemble(\n","            self.window_size, self.n_estimators, self.random_state)\n","        self.ensemble = iforest\n","        self.ensemble.fit(window)\n","        # self.nb_update = self.nb_update + 1\n","        print(\"\")\n","        print(\"The model was updated by training a new iForest with the version : \"+self.version)\n","\n","    def anomaly_scores_rate(self, window):\n","        \"\"\"\n","        Given a 2D matrix of observations, compute the anomaly rate \n","        for all instances in the window and return an anomaly rate of the given window.\n","\n","        Parameters :\n","        window: numpy.ndarray of shape (self.window_size, n_features)\n","        \"\"\"\n","\n","        score_tab = 2.0 ** (-1.0 *\n","                            self.ensemble.path_length(window) / c(len(window)))\n","        score = 0\n","        for x in score_tab:\n","            if x > self.anomaly_threshold:\n","                score += 1\n","        return score / len(score_tab)\n","\n","    '''\n","      MAJ : 21112020\n","      By : Maurras\n","      Add new function to classify instances (anomaly or normal)\n","  '''\n","\n","    def predict_simple(self, X):\n","        \"\"\"\n","        Given a window, Predict the instance class (1 or 0) by using predict_from_instances_scores on our model\n","\n","        \"\"\"\n","        # print('predict_simple')\n","        prediction = self.ensemble.predict_from_instances_scores(self.ensemble.anomaly_score(X),\n","                                                                 self.anomaly_threshold)  # return prediction of all instances\n","\n","        # print('end predict_simple')\n","        return prediction\n","\n","    def predict(self, X):\n","        \"\"\"\n","        Given an instance, Predict the anomaly (1 or 0) based on the last sample of the window by using predict_proba if our model have fit, \n","        else return None\n","\n","        \"\"\"\n","        if (self.samples_seen <= self.window_size):\n","\n","            return [-1]  # Return the last element\n","\n","        X = np.reshape(X, (1, len(X[0])))\n","        # Append the instances in the sliding window\n","        self.prec_window = np.concatenate((self.prec_window, X))\n","\n","        prediction = self.ensemble.predict_from_anomaly_scores(\n","            self.predict_proba(self.prec_window), self.anomaly_threshold)  # return 0 or 1\n","\n","        return [prediction]\n","\n","    def predict_proba(self, X):\n","        \"\"\"\n","        Calculate the anomaly score of the window if our model have fit, else return None\n","        Parameters :\n","        X: numpy.ndarray of shape (self.window_size, n_features)   \n","\n","        \"\"\"\n","        if (self.samples_seen <= self.window_size):\n","            return [-1]\n","        # Anomaly return an array with all scores of each data, taking -1 return the last instance (X) anomaly score\n","        return self.ensemble.anomaly_score(self.prec_window)[-1]\n","\n","\n","\"\"\"# Part 2- IsolationTreeEnsemble  Class (iForest in the original paper)\"\"\"\n","\n","# Follows original paper algo from https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/icdm08b.pdf\n","# Original Source re-used and adpted to our project from https://github.com/Divya-Bhargavi/isolation-forest\n","\n","\n","class IsolationTreeEnsemble:\n","    def __init__(self, sample_size, n_trees, random_state):\n","        self.sample_size = sample_size\n","        self.n_trees = n_trees\n","        self.depth = np.log2(sample_size)\n","        self.trees = []\n","        self.random_state = random_state\n","        self._random_state = check_random_state(self.random_state)\n","        self.is_learning_phase_on = True\n","\n","    def fit(self, X: np.ndarray):\n","        \"\"\"\n","        Given a 2D matrix of observations, create an ensemble of IsolationTree\n","        objects and store them in a list: self.trees.  Convert DataFrames to\n","        ndarray objects.\n","        \"\"\"\n","        len_x = len(X)\n","\n","        for i in range(self.n_trees):\n","            sample_idx = random.sample(list(range(len_x)), self.sample_size)\n","            temp_tree = IsolationTree(self.depth, 0).fit(X[sample_idx])\n","            self.trees.append(temp_tree)\n","\n","        return self\n","\n","    def path_length(self, X: np.ndarray):\n","        \"\"\"\n","        Given a 2D matrix of observations, X, compute the average path length\n","        for each observation in X.  Compute the path length for x_i using every\n","        tree in self.trees then compute the average for each x_i.  Return an\n","        ndarray of shape (len(X),1).\n","        \"\"\"\n","        pl_vector = []\n","\n","        for x in (X):\n","            pl = np.array([path_length_tree(x, t, 0) for t in self.trees])\n","            pl = pl.mean()\n","\n","            pl_vector.append(pl)\n","\n","        pl_vector = np.array(pl_vector).reshape(-1, 1)\n","\n","        return pl_vector\n","\n","    def anomaly_score(self, X: np.ndarray):\n","        \"\"\"\n","        Given a 2D matrix of observations, X, compute the anomaly score\n","        for each x_i observation, returning an ndarray of them.\n","        \"\"\"\n","        return 2.0 ** (-1.0 * self.path_length(X) / c(len(X)))\n","\n","    def predict_from_anomaly_scores(self, scores: int, threshold: float):\n","        \"\"\"\n","        Given an array of scores and a score threshold, return an array of\n","        the predictions: 1 for any score >= the threshold and 0 otherwise.\n","        \"\"\"\n","        predictions = 1 if scores >= threshold else 0\n","\n","        return predictions\n","\n","    '''\n","          MAJ : 21112020\n","          By : Maurras\n","          Add new function to classify instances (anomaly or normal)\n","    '''\n","\n","    def predict_from_instances_scores(self, scores: np.ndarray, threshold: float) -> np.ndarray:\n","        \"\"\"\n","        Given an array of scores and a score threshold, return an array of\n","        the predictions: -1 for any score >= the threshold and 1 otherwise.\n","        \"\"\"\n","\n","        predictions = [1 if p[0] >= threshold else 0 for p in scores]\n","\n","        return predictions\n","\n","\n","class IsolationTree:\n","    def __init__(self, height_limit, current_height):\n","\n","        self.depth = height_limit\n","        self.current_height = current_height\n","        self.split_by = None\n","        self.split_value = None\n","        self.right = None\n","        self.left = None\n","        self.size = 0\n","        self.exnodes = 0\n","        self.n_nodes = 1\n","\n","    def fit(self, X: np.ndarray):\n","        \"\"\"\n","        Given a 2D matrix of observations, create an isolation tree. Set field\n","        self.root to the root of that tree and return it.\n","        If you are working on an improved algorithm, check parameter \"improved\"\n","        and switch to your new functionality else fall back on your original code.\n","        \"\"\"\n","\n","        if len(X) <= 1 or self.current_height >= self.depth:\n","            self.exnodes = 1\n","            self.size = X.shape[0]\n","\n","            return self\n","\n","        split_by = random.choice(np.arange(X.shape[1]))\n","        X_col = X[:, split_by]\n","        min_x = X_col.min()\n","        max_x = X_col.max()\n","\n","        # TODO MAJ: MAurras 03112020 = Revoir ce bout de code : ça pourrait créer des problèmes\n","        if min_x == max_x:\n","            self.exnodes = 1\n","            self.size = len(X)\n","\n","            return self\n","\n","        else:\n","\n","            split_value = min_x + \\\n","                random.betavariate(0.5, 0.5) * (max_x - min_x)\n","\n","            w = np.where(X_col < split_value, True, False)\n","            del X_col\n","\n","            self.size = X.shape[0]\n","            self.split_by = split_by\n","            self.split_value = split_value\n","\n","            self.left = IsolationTree(\n","                self.depth, self.current_height + 1).fit(X[w])\n","            self.right = IsolationTree(\n","                self.depth, self.current_height + 1).fit(X[~w])\n","            self.n_nodes = self.left.n_nodes + self.right.n_nodes + 1\n","\n","        return self\n","\n","\n","def c(n):\n","    if n > 2:\n","        return 2.0*(np.log(n-1)+0.5772156649) - (2.0*(n-1.)/(n*1.0))\n","    elif n == 2:\n","        return 1\n","    if n == 1:\n","        return 0\n","\n","\n","def path_length_tree(x, t, e):\n","    e = e\n","    if t.exnodes == 1:\n","        e = e + c(t.size)\n","        return e\n","    else:\n","        a = t.split_by\n","        if x[a] < t.split_value:\n","            return path_length_tree(x, t.left, e+1)\n","        if x[a] >= t.split_value:\n","            return path_length_tree(x, t.right, e+1)\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-03-30T10:22:23.429348Z","iopub.status.busy":"2023-03-30T10:22:23.428378Z","iopub.status.idle":"2023-03-30T10:22:29.140274Z","shell.execute_reply":"2023-03-30T10:22:29.138463Z","shell.execute_reply.started":"2023-03-30T10:22:23.429306Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Time</th>\n","      <th>V1</th>\n","      <th>V2</th>\n","      <th>V3</th>\n","      <th>V4</th>\n","      <th>V5</th>\n","      <th>V6</th>\n","      <th>V7</th>\n","      <th>V8</th>\n","      <th>V9</th>\n","      <th>...</th>\n","      <th>V21</th>\n","      <th>V22</th>\n","      <th>V23</th>\n","      <th>V24</th>\n","      <th>V25</th>\n","      <th>V26</th>\n","      <th>V27</th>\n","      <th>V28</th>\n","      <th>Amount</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>-1.359807</td>\n","      <td>-0.072781</td>\n","      <td>2.536347</td>\n","      <td>1.378155</td>\n","      <td>-0.338321</td>\n","      <td>0.462388</td>\n","      <td>0.239599</td>\n","      <td>0.098698</td>\n","      <td>0.363787</td>\n","      <td>...</td>\n","      <td>-0.018307</td>\n","      <td>0.277838</td>\n","      <td>-0.110474</td>\n","      <td>0.066928</td>\n","      <td>0.128539</td>\n","      <td>-0.189115</td>\n","      <td>0.133558</td>\n","      <td>-0.021053</td>\n","      <td>149.62</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>1.191857</td>\n","      <td>0.266151</td>\n","      <td>0.166480</td>\n","      <td>0.448154</td>\n","      <td>0.060018</td>\n","      <td>-0.082361</td>\n","      <td>-0.078803</td>\n","      <td>0.085102</td>\n","      <td>-0.255425</td>\n","      <td>...</td>\n","      <td>-0.225775</td>\n","      <td>-0.638672</td>\n","      <td>0.101288</td>\n","      <td>-0.339846</td>\n","      <td>0.167170</td>\n","      <td>0.125895</td>\n","      <td>-0.008983</td>\n","      <td>0.014724</td>\n","      <td>2.69</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>-1.358354</td>\n","      <td>-1.340163</td>\n","      <td>1.773209</td>\n","      <td>0.379780</td>\n","      <td>-0.503198</td>\n","      <td>1.800499</td>\n","      <td>0.791461</td>\n","      <td>0.247676</td>\n","      <td>-1.514654</td>\n","      <td>...</td>\n","      <td>0.247998</td>\n","      <td>0.771679</td>\n","      <td>0.909412</td>\n","      <td>-0.689281</td>\n","      <td>-0.327642</td>\n","      <td>-0.139097</td>\n","      <td>-0.055353</td>\n","      <td>-0.059752</td>\n","      <td>378.66</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3 rows × 31 columns</p>\n","</div>"],"text/plain":["   Time        V1        V2        V3        V4        V5        V6        V7  \\\n","0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n","1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n","2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n","\n","         V8        V9  ...       V21       V22       V23       V24       V25  \\\n","0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n","1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n","2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n","\n","        V26       V27       V28  Amount  Class  \n","0 -0.189115  0.133558 -0.021053  149.62      0  \n","1  0.125895 -0.008983  0.014724    2.69      0  \n","2 -0.139097 -0.055353 -0.059752  378.66      0  \n","\n","[3 rows x 31 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv('/kaggle/input/credit-card-fraud-detection/creditcard.csv')\n","df.head(3)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-03-30T10:22:29.144489Z","iopub.status.busy":"2023-03-30T10:22:29.143475Z","iopub.status.idle":"2023-03-30T10:22:29.225377Z","shell.execute_reply":"2023-03-30T10:22:29.223282Z","shell.execute_reply.started":"2023-03-30T10:22:29.144433Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>V1</th>\n","      <th>V2</th>\n","      <th>V3</th>\n","      <th>V4</th>\n","      <th>V5</th>\n","      <th>V6</th>\n","      <th>V7</th>\n","      <th>V8</th>\n","      <th>V9</th>\n","      <th>V10</th>\n","      <th>...</th>\n","      <th>V20</th>\n","      <th>V21</th>\n","      <th>V22</th>\n","      <th>V23</th>\n","      <th>V24</th>\n","      <th>V25</th>\n","      <th>V26</th>\n","      <th>V27</th>\n","      <th>V28</th>\n","      <th>Amount</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-1.359807</td>\n","      <td>-0.072781</td>\n","      <td>2.536347</td>\n","      <td>1.378155</td>\n","      <td>-0.338321</td>\n","      <td>0.462388</td>\n","      <td>0.239599</td>\n","      <td>0.098698</td>\n","      <td>0.363787</td>\n","      <td>0.090794</td>\n","      <td>...</td>\n","      <td>0.251412</td>\n","      <td>-0.018307</td>\n","      <td>0.277838</td>\n","      <td>-0.110474</td>\n","      <td>0.066928</td>\n","      <td>0.128539</td>\n","      <td>-0.189115</td>\n","      <td>0.133558</td>\n","      <td>-0.021053</td>\n","      <td>149.62</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.191857</td>\n","      <td>0.266151</td>\n","      <td>0.166480</td>\n","      <td>0.448154</td>\n","      <td>0.060018</td>\n","      <td>-0.082361</td>\n","      <td>-0.078803</td>\n","      <td>0.085102</td>\n","      <td>-0.255425</td>\n","      <td>-0.166974</td>\n","      <td>...</td>\n","      <td>-0.069083</td>\n","      <td>-0.225775</td>\n","      <td>-0.638672</td>\n","      <td>0.101288</td>\n","      <td>-0.339846</td>\n","      <td>0.167170</td>\n","      <td>0.125895</td>\n","      <td>-0.008983</td>\n","      <td>0.014724</td>\n","      <td>2.69</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-1.358354</td>\n","      <td>-1.340163</td>\n","      <td>1.773209</td>\n","      <td>0.379780</td>\n","      <td>-0.503198</td>\n","      <td>1.800499</td>\n","      <td>0.791461</td>\n","      <td>0.247676</td>\n","      <td>-1.514654</td>\n","      <td>0.207643</td>\n","      <td>...</td>\n","      <td>0.524980</td>\n","      <td>0.247998</td>\n","      <td>0.771679</td>\n","      <td>0.909412</td>\n","      <td>-0.689281</td>\n","      <td>-0.327642</td>\n","      <td>-0.139097</td>\n","      <td>-0.055353</td>\n","      <td>-0.059752</td>\n","      <td>378.66</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.966272</td>\n","      <td>-0.185226</td>\n","      <td>1.792993</td>\n","      <td>-0.863291</td>\n","      <td>-0.010309</td>\n","      <td>1.247203</td>\n","      <td>0.237609</td>\n","      <td>0.377436</td>\n","      <td>-1.387024</td>\n","      <td>-0.054952</td>\n","      <td>...</td>\n","      <td>-0.208038</td>\n","      <td>-0.108300</td>\n","      <td>0.005274</td>\n","      <td>-0.190321</td>\n","      <td>-1.175575</td>\n","      <td>0.647376</td>\n","      <td>-0.221929</td>\n","      <td>0.062723</td>\n","      <td>0.061458</td>\n","      <td>123.50</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-1.158233</td>\n","      <td>0.877737</td>\n","      <td>1.548718</td>\n","      <td>0.403034</td>\n","      <td>-0.407193</td>\n","      <td>0.095921</td>\n","      <td>0.592941</td>\n","      <td>-0.270533</td>\n","      <td>0.817739</td>\n","      <td>0.753074</td>\n","      <td>...</td>\n","      <td>0.408542</td>\n","      <td>-0.009431</td>\n","      <td>0.798278</td>\n","      <td>-0.137458</td>\n","      <td>0.141267</td>\n","      <td>-0.206010</td>\n","      <td>0.502292</td>\n","      <td>0.219422</td>\n","      <td>0.215153</td>\n","      <td>69.99</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 29 columns</p>\n","</div>"],"text/plain":["         V1        V2        V3        V4        V5        V6        V7  \\\n","0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n","1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n","2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n","3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n","4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n","\n","         V8        V9       V10  ...       V20       V21       V22       V23  \\\n","0  0.098698  0.363787  0.090794  ...  0.251412 -0.018307  0.277838 -0.110474   \n","1  0.085102 -0.255425 -0.166974  ... -0.069083 -0.225775 -0.638672  0.101288   \n","2  0.247676 -1.514654  0.207643  ...  0.524980  0.247998  0.771679  0.909412   \n","3  0.377436 -1.387024 -0.054952  ... -0.208038 -0.108300  0.005274 -0.190321   \n","4 -0.270533  0.817739  0.753074  ...  0.408542 -0.009431  0.798278 -0.137458   \n","\n","        V24       V25       V26       V27       V28  Amount  \n","0  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62  \n","1 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69  \n","2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66  \n","3 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50  \n","4  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99  \n","\n","[5 rows x 29 columns]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["X = df.drop(['Time', 'Class'], axis=1)\n","X.head()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-03-30T10:22:29.227999Z","iopub.status.busy":"2023-03-30T10:22:29.227433Z","iopub.status.idle":"2023-03-30T10:22:29.240100Z","shell.execute_reply":"2023-03-30T10:22:29.237317Z","shell.execute_reply.started":"2023-03-30T10:22:29.227948Z"},"trusted":true},"outputs":[{"data":{"text/plain":["((284807,), (284807, 29))"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["y = np.zeros(X.shape[0])\n","y.shape, X.shape"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-03-30T10:22:29.243484Z","iopub.status.busy":"2023-03-30T10:22:29.242715Z","iopub.status.idle":"2023-03-30T10:22:29.252919Z","shell.execute_reply":"2023-03-30T10:22:29.251280Z","shell.execute_reply.started":"2023-03-30T10:22:29.243421Z"},"trusted":true},"outputs":[],"source":["IfA = IsolationForestStream(326, 25, random_state=10)\n"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-03-30T10:26:26.416057Z","iopub.status.busy":"2023-03-30T10:26:26.415500Z","iopub.status.idle":"2023-03-30T10:26:26.423580Z","shell.execute_reply":"2023-03-30T10:26:26.421959Z","shell.execute_reply.started":"2023-03-30T10:26:26.415988Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["284807\n"]}],"source":["import tqdm\n","print(X.shape[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-30T10:26:47.455618Z","iopub.status.busy":"2023-03-30T10:26:47.455070Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["96162it [2:49:54,  6.89it/s]"]}],"source":["scores = []\n","for x,s in tqdm.tqdm(zip(X.to_numpy(), y)):\n","    IfA = IfA.partial_fit(np.array([x]), [s])\n","    scores.append(IfA.predict([x]))\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X.shape"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-03-30T08:38:09.731859Z","iopub.status.busy":"2023-03-30T08:38:09.731448Z","iopub.status.idle":"2023-03-30T08:38:09.745389Z","shell.execute_reply":"2023-03-30T08:38:09.743574Z","shell.execute_reply.started":"2023-03-30T08:38:09.731823Z"},"trusted":true},"outputs":[],"source":["df1 = pd.DataFrame({'IForestASD':scores})\n","df1.to_csv('test.csv', index=False)"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-03-30T08:48:59.882762Z","iopub.status.busy":"2023-03-30T08:48:59.882307Z","iopub.status.idle":"2023-03-30T08:48:59.892574Z","shell.execute_reply":"2023-03-30T08:48:59.891233Z","shell.execute_reply.started":"2023-03-30T08:48:59.882720Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[[100]]\n"]}],"source":["from sklearn.metrics import confusion_matrix\n","s = np.array(np.where(np.array(scores)==-1, 0, 1))\n","print(confusion_matrix(df['Class'], s))"]}],"metadata":{"kernelspec":{"display_name":"venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"vscode":{"interpreter":{"hash":"e6184978c8ad2882c04f1ebea5fb70732f00f9f3b207d8b1b4fa7938a9d92185"}}},"nbformat":4,"nbformat_minor":4}
